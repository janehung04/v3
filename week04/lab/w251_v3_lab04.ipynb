{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w251_v3_lab04.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0Ej9327K46p"
      },
      "source": [
        "In this lab we will experiment with some of the deep learning concepts covered in the async material, and beyond. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eefV8lZLPts"
      },
      "source": [
        "# Import necessary packages. \n",
        "import torch, torch.nn as nn\n",
        "from PIL import Image\n",
        "torch.manual_seed(1)\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2zGYLpWRwPc"
      },
      "source": [
        "### MSE Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6U5hq8rL8g3",
        "outputId": "6a162edb-df1b-408d-b767-3def297aff26"
      },
      "source": [
        "ypred = torch.arange(-5, 5).float()\n",
        "yact = torch.randint(2, (len(ypred),)).float()\n",
        "print(f'Dummy predicted values : {ypred}')\n",
        "print(f'Dummy actual values : {yact}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy predicted values : tensor([-5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])\n",
            "Dummy actual values : tensor([1., 1., 0., 0., 1., 1., 1., 1., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWOJdMGOQipr",
        "outputId": "da212dd7-61ff-4519-a33b-cc454d73f23e"
      },
      "source": [
        "criterion = torch.nn.MSELoss(reduction='none')\n",
        "loss = criterion(ypred, yact)\n",
        "print(f'MSE loss for each element {loss}')\n",
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "loss = criterion(ypred, yact)\n",
        "print(f'MSE loss averaged {loss:.5f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE loss for each element tensor([36., 25.,  9.,  4.,  4.,  1.,  0.,  1.,  4., 16.])\n",
            "MSE loss averaged 10.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdaVQIjrRyDv"
      },
      "source": [
        "### Binary Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d2sa3zaR298",
        "outputId": "7ca31c34-079a-4c76-fa38-703653d957b0"
      },
      "source": [
        "ypred = torch.rand(10).float()\n",
        "yact = torch.randint(2, (len(ypred),)).float()\n",
        "print(f'Dummy predicted values : {ypred}')\n",
        "print(f'Dummy actual values : {yact}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy predicted values : tensor([0.6387, 0.5247, 0.6826, 0.3051, 0.4635, 0.4550, 0.5725, 0.4980, 0.9371,\n",
            "        0.6556])\n",
            "Dummy actual values : tensor([0., 1., 0., 0., 1., 0., 0., 0., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajQhLBkb1HhS"
      },
      "source": [
        "Find the Binary Cross Entropy loss between the two vectors.\n",
        "You can find the loss functions [here](https://pytorch.org/docs/stable/nn.html).  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwAbwAr81tOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65e7e41-4783-4ac7-ac8e-dd86fa462ff1"
      },
      "source": [
        "# Binaray Cross entropy loss....\n",
        "m = nn.Sigmoid()\n",
        "criterion = nn.BCELoss()\n",
        "loss = criterion(m(ypred), yact)\n",
        "print(f'Cross entropy loss for each element {loss}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross entropy loss for each element 0.8307626843452454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjZGDAri1zFc"
      },
      "source": [
        "### Multi Layer Perceptron Forward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5D0uaGV2h-M"
      },
      "source": [
        "# Lets initialise a MLP \n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(2, 2, bias = False), \n",
        "            nn.Linear(2, 1, bias = False))\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azBaCsap3Me8"
      },
      "source": [
        "net1 = MLP()\n",
        "x = torch.rand(2).float()\n",
        "with torch.no_grad(): out = net1(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwvD7e1f4e7P",
        "outputId": "bf544ce8-5124-40fe-f3d2-fa4a2805394b"
      },
      "source": [
        "print(f'Input to net : {x}')\n",
        "print('-'*50)\n",
        "print(f'Layer 0 parameters {net1.layers[0].weight}')\n",
        "print(f'Layer 1 parameters {net1.layers[1].weight}')\n",
        "print('-'*50)\n",
        "print(f'Output : {out}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to net : tensor([0.3971, 0.7544])\n",
            "--------------------------------------------------\n",
            "Layer 0 parameters Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121],\n",
            "        [-0.1371,  0.3319]], requires_grad=True)\n",
            "Layer 1 parameters Parameter containing:\n",
            "tensor([[-0.6657,  0.4241]], requires_grad=True)\n",
            "--------------------------------------------------\n",
            "Output : tensor([0.1435])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU-GjDpj9QDf"
      },
      "source": [
        "Can you calculate through matrix multiplication ?   \n",
        "Tip, you can use the torch.matmul function to multiply matrices, or alternatively check [this](https://stackoverflow.com/questions/60275705/how-to-calculate-a-forward-pass-with-matrix-operations-in-pytorch) link for calculating a forward pass. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWqHluq87YM-"
      },
      "source": [
        "# You can enter your calculations here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY9btQJ-46B8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394d4912-879e-4552-f108-15a7cb2a3b81"
      },
      "source": [
        "net1.layers[1].weight @ (net1.layers[0].weight @ x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1435], grad_fn=<MvBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V93t3NfX-GXa"
      },
      "source": [
        "### Multi Layer Perceptron Forward Pass with bias term\n",
        "If we add the bias term can you calculate to forward pass now ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70hdVk_X8YBN"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(2, 2, bias = True), \n",
        "            #nn.ReLU(),\n",
        "            nn.Linear(2, 1, bias = True))\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2soIoUFA7wro"
      },
      "source": [
        "net2 = MLP()\n",
        "with torch.no_grad(): out = net2(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e10yvyLP6wvG",
        "outputId": "c4d7fcdf-91f7-4fcb-ac68-09a33cce365d"
      },
      "source": [
        "print(f'Input to net : {x}')\n",
        "print('-'*50)\n",
        "print(f'Layer 0 parameters {net2.layers[0].weight}')\n",
        "print(f'Layer 0 bias       {net2.layers[0].bias}\\n')\n",
        "print(f'Layer 1 parameters {net2.layers[1].weight}')\n",
        "print(f'Layer 1 bias       {net2.layers[1].bias}\\n')\n",
        "print('-'*50)\n",
        "print(f'Output : {out}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to net : tensor([0.3971, 0.7544])\n",
            "--------------------------------------------------\n",
            "Layer 0 parameters Parameter containing:\n",
            "tensor([[ 0.0983, -0.0866],\n",
            "        [ 0.1961,  0.0349]], requires_grad=True)\n",
            "Layer 0 bias       Parameter containing:\n",
            "tensor([ 0.2583, -0.2756], requires_grad=True)\n",
            "\n",
            "Layer 1 parameters Parameter containing:\n",
            "tensor([[-0.0516, -0.0637]], requires_grad=True)\n",
            "Layer 1 bias       Parameter containing:\n",
            "tensor([0.1025], requires_grad=True)\n",
            "\n",
            "--------------------------------------------------\n",
            "Output : tensor([0.1014])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldn3WAhJ-eQC"
      },
      "source": [
        "# You can enter your calculations here. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td2diDZd_Xqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4e204e-e836-4d74-c66f-6c7c8856518f"
      },
      "source": [
        "net2.layers[1].weight @ (net2.layers[0].weight @ x + net2.layers[0].bias) + net2.layers[1].bias "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1014], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdyAZWJlAacs"
      },
      "source": [
        "### Multi Layer Perceptron Forward Pass with Relu\n",
        "If we add a RELU activation, can you calculate the forward pass now ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q19RFTcXAdHf"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(2, 2, bias = True), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2, 1, bias = True))\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnqYBt_5Ahsq"
      },
      "source": [
        "net3 = MLP()\n",
        "with torch.no_grad(): out = net3(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHKF-GjpAlPq",
        "outputId": "ad496bd7-9a35-4eba-f436-20da1d7fcf17"
      },
      "source": [
        "print(f'Input to net : {x}')\n",
        "print('-'*50)\n",
        "print(f'Layer 0 parameters {net3.layers[0].weight}')\n",
        "print(f'Layer 0 bias       {net3.layers[0].bias}\\n')\n",
        "print(f'Layer 1 parameters {net3.layers[2].weight}')\n",
        "print(f'Layer 1 bias       {net3.layers[2].bias}\\n')\n",
        "print('-'*50)\n",
        "print(f'Output : {out}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to net : tensor([0.3971, 0.7544])\n",
            "--------------------------------------------------\n",
            "Layer 0 parameters Parameter containing:\n",
            "tensor([[-0.0028,  0.6181],\n",
            "        [ 0.2200, -0.2633]], requires_grad=True)\n",
            "Layer 0 bias       Parameter containing:\n",
            "tensor([-0.4271, -0.1185], requires_grad=True)\n",
            "\n",
            "Layer 1 parameters Parameter containing:\n",
            "tensor([[-0.3050, -0.2266]], requires_grad=True)\n",
            "Layer 1 bias       Parameter containing:\n",
            "tensor([0.0339], requires_grad=True)\n",
            "\n",
            "--------------------------------------------------\n",
            "Output : tensor([0.0222])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0iWatl0Avxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89a311d-4cbf-4b5c-8126-d428e8c3090b"
      },
      "source": [
        "# You can enter your calculations here. \n",
        "m = nn.ReLU()\n",
        "m(net3.layers[2].weight @ m(net3.layers[0].weight @ x + net3.layers[0].bias) + net3.layers[2].bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0222], grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqsSWMlYU-e-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}